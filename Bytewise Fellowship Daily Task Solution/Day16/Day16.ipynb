{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import streamlit as st\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "\n",
    "# Task 1: Apply K-Means clustering and visualize the clusters\n",
    "def kmeans_clustering():\n",
    "    st.title(\"K-Means Clustering on Iris Dataset\")\n",
    "    st.write(\"### Apply K-Means clustering to the Iris dataset and visualize the clusters using a scatter plot of two features.\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    data['cluster'] = kmeans.fit_predict(data.iloc[:, :-1])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=data['sepal length (cm)'], y=data['sepal width (cm)'], hue=data['cluster'], palette='viridis', ax=ax)\n",
    "    plt.xlabel('Sepal Length')\n",
    "    plt.ylabel('Sepal Width')\n",
    "    plt.title('K-Means Clustering of Iris Dataset')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# Task 2: Use the Elbow Method and Silhouette Score to determine the optimal number of clusters\n",
    "def optimal_clusters():\n",
    "    st.title(\"Choosing the Optimal Number of Clusters\")\n",
    "    st.write(\"### Use the Elbow Method and Silhouette Score to determine the optimal number of clusters for the Iris dataset.\")\n",
    "\n",
    "    # Elbow Method\n",
    "    distortions = []\n",
    "    K = range(1, 11)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeanModel.fit(data.iloc[:, :-1])\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('Elbow Method showing the optimal k')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # Silhouette Score\n",
    "    st.write(\"### Silhouette Scores for different number of clusters\")\n",
    "    silhouette_avg = []\n",
    "    for k in K[1:]:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(data.iloc[:, :-1])\n",
    "        cluster_labels = kmeans.labels_\n",
    "        silhouette_avg.append(silhouette_score(data.iloc[:, :-1], cluster_labels))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(K[1:], silhouette_avg, 'bx-')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette score')\n",
    "    plt.title('Silhouette scores for different number of clusters')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# Task 3: Use PCA to reduce the Iris dataset to two dimensions and visualize the clusters\n",
    "def pca_visualization():\n",
    "    st.title(\"Cluster Visualization with PCA\")\n",
    "    st.write(\"### Use Principal Component Analysis (PCA) to reduce the Iris dataset to two dimensions and visualize the clusters obtained from K-Means clustering in the PCA-reduced space.\")\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(data.iloc[:, :-1])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    data['pca_cluster'] = kmeans.fit_predict(data.iloc[:, :-1])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=components[:, 0], y=components[:, 1], hue=data['pca_cluster'], palette='viridis', ax=ax)\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('PCA Visualization of K-Means Clustering')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# Task 4: Implement hierarchical clustering and plot a dendrogram\n",
    "def hierarchical_clustering():\n",
    "    st.title(\"Hierarchical Clustering: Dendrogram\")\n",
    "    st.write(\"### Implement hierarchical clustering using the Iris dataset and plot a dendrogram to visualize the clustering process.\")\n",
    "\n",
    "    linked = linkage(data.iloc[:, :-1], method='ward')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    dendrogram(linked, orientation='top', labels=iris.target_names[data['species']], distance_sort='descending', show_leaf_counts=True)\n",
    "    plt.title('Dendrogram for Hierarchical Clustering')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# Task 5: Compare the performance of K-Means and Agglomerative Hierarchical Clustering\n",
    "def compare_clustering_algorithms():\n",
    "    st.title(\"Comparing Clustering Algorithms\")\n",
    "    st.write(\"### Compare the performance of K-Means and Agglomerative Hierarchical Clustering on the Iris dataset.\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(data.iloc[:, :-1])\n",
    "\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=3)\n",
    "    agglomerative_clusters = agglomerative.fit_predict(data.iloc[:, :-1])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    sns.scatterplot(x=data['sepal length (cm)'], y=data['sepal width (cm)'], hue=kmeans_clusters, palette='viridis', ax=ax[0])\n",
    "    ax[0].set_title('K-Means Clustering')\n",
    "    sns.scatterplot(x=data['sepal length (cm)'], y=data['sepal width (cm)'], hue=agglomerative_clusters, palette='viridis', ax=ax[1])\n",
    "    ax[1].set_title('Agglomerative Clustering')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    st.write(\"### K-Means Clustering vs Agglomerative Clustering\")\n",
    "    st.write(\"K-Means Clustering strengths: Efficient, well-defined clusters, sensitive to initial centroids.\")\n",
    "    st.write(\"Agglomerative Clustering strengths: Can form complex clusters, no need to specify number of clusters, sensitive to noise and outliers.\")\n",
    "\n",
    "# Create the Streamlit sidebar for navigation\n",
    "st.sidebar.title(\"Clustering Tasks\")\n",
    "task = st.sidebar.radio(\"Select Task\", ('K-Means Clustering', 'Optimal Clusters', 'PCA Visualization', 'Hierarchical Clustering', 'Compare Clustering Algorithms'))\n",
    "\n",
    "if task == 'K-Means Clustering':\n",
    "    kmeans_clustering()\n",
    "elif task == 'Optimal Clusters':\n",
    "    optimal_clusters()\n",
    "elif task == 'PCA Visualization':\n",
    "    pca_visualization()\n",
    "elif task == 'Hierarchical Clustering':\n",
    "    hierarchical_clustering()\n",
    "elif task == 'Compare Clustering Algorithms':\n",
    "    compare_clustering_algorithms()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
